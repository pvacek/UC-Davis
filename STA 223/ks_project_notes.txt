#223 Project

#Current state: Analyze the July 2014 K.S. projects. (Is this ideal? Should we examine another month)

#1. Method: Use Lasso regularization to determine significant and non-significant sub-categories
##Should this be done on only the Jul. 2014 data? What about all the data?
##This seems to have helped, although perhaps a more significant method would have done.

#2. Start examining auxiliary features from Kickstarter via ID linking.
##Build a model with and without? Which features are kept? Do these additional features help explain success?

#3. Please for the love of god do residual and diagnostic analysis on every model that you end up using.
##Seriously

###OBSERVATIONS SO FAR###
#1. Nesting the categories seems to have worked
#2. I need to find out how to create a nested model for the GLM. Is it necessary?

###2/24###
#1. Lasso: Measure goodness of fit?
#2. Full model: Seems to be overfitting. How can I improve goodness of fit?
#3. Are there any specific procedures I should avoid if I am interested in predictive power (AUC)
#should I still worry about goodness of fit? To what extent?
#4. Here's a dilemma: should I choose to analyze the 'most successful' or the 'hardest-to-predict' categories?
#5. Should I keep using normalized log goal after switching to subcategory?